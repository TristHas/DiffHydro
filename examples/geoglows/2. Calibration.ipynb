{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af18f22f-4b12-40f6-8eb6-b4ffd61b86a4",
   "metadata": {},
   "source": [
    "### Ideas of what we have to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bc63c2-f6bc-4c9d-8e42-499931b21086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imports import *\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, \"./DiffHydro\")\n",
    "sys.path.insert(0, \"./DiffRoute\")\n",
    "\n",
    "from diffhydro import (TimeSeriesThDF, RivTree, RivTreeCluster,\n",
    "                       StagedCatchmentInterpolator, CatchmentInterpolator) \n",
    "from diffhydro.pipelines import CalibrationRouter\n",
    "from diffhydro.utils import nse_fn\n",
    "\n",
    "from diffroute.io import read_rapid_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7801fc2-e1ed-4b1e-9502-17025895b136",
   "metadata": {},
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3981f855-743a-4b3c-8e55-1d164bdbe8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plength_thr=10**4\n",
    "node_thr=10**4\n",
    "\n",
    "model_name=\"muskingum\"\n",
    "time_window = max_delay = 30\n",
    "dt = 1/24\n",
    "\n",
    "epochs = 500\n",
    "n_iter = 100\n",
    "device = \"cuda:6\"\n",
    "vpu = \"604\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7553e461-aaf2-44bf-a578-38651676b974",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Upstream stats computations ... ####\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba1d7d6a68244329c776fa2cf865ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing breakpoints:   0%|          | 0/32717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Segmentation into subgraphs ... ####\n",
      "Removing edges...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4deee72a10428aa9d3585eae45f3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment graph into connected components....\n",
      "Build subgraphs for each cluster and node-cluster map...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2dc0c165d94d7d81349adbbc869a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establish dependencies between clusters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ed9dbf2238473e81fbaa14b5180f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Grouping subgraphs to cluster and infering dependencies ... ####\n",
      "Initialize dependencies...\n",
      "Associate clusters for remaining subgraphs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0c81874b8442c7a45c90bfe1187921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging graphs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2522d7a9f3ca451c983e5fad8babaa24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing merged graphs node idxs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02b9a88a7d04cb0a8af5438dc8683ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match breakpoint nodes across clusters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e603c5d6c114778b2a37b5fd2f1eef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(g, interp_df,\n",
    " tr_runoff_pix, te_runoff_pix, \n",
    " tr_discharge, te_discharge) = init_calib_exp(vpu, \"1980\", plength_thr, node_thr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090ba0ad-7d18-462a-a474-5ee8bbd99aeb",
   "metadata": {},
   "source": [
    "### Small VPU can be optimized over in a single forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4768704-a32a-4832-91fc-e35520adb8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = CatchmentInterpolator(g, tr_runoff_pix, interp_df).to(device)\n",
    "tr_runoff = ci.interpolate_runoff(tr_runoff_pix)\n",
    "te_runoff = ci.interpolate_runoff(te_runoff_pix)\n",
    "\n",
    "tr_y = tr_discharge\n",
    "te_y = te_discharge\n",
    "\n",
    "model = CalibrationRouter(g, max_delay, dt).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c3288-79d8-4bf4-b21b-6dffc91eaf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    pbar=tqdm(range(n_iter), desc=\"Training\")\n",
    "    \n",
    "    for i in pbar:\n",
    "        out = model(tr_runoff)\n",
    "        \n",
    "        tr_nse = nse_fn(out.values, tr_y.values).mean()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss = 1-tr_nse\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        out = model(te_runoff)\n",
    "        te_nse = nse_fn(out.values, te_y.values).mean()\n",
    "        \n",
    "        pbar.set_postfix({\"Tr NSE:\": tr_nse.item(), \"Te NSE\":te_nse.item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87401e0-a248-496e-a603-97d0a7d37dc0",
   "metadata": {},
   "source": [
    "### Large graphs need to be optimized sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd8df90-0cda-4847-925a-b4f78da713d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01a75bfd564470999695c20149a8671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ci = StagedCatchmentInterpolator(g, tr_runoff_pix, interp_df).to(device)\n",
    "model = CalibrationRouter(g, max_delay, dt).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a54d3f-3b2b-4f0e-b445-d83ce04ec6cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f0ddf147434ce0a1906a92fa6c85af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f8a2ca2e9b4f949f2817b73fafef32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m opt.zero_grad()\n\u001b[32m     24\u001b[39m loss = \u001b[32m1\u001b[39m-tr_nse\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m opt.step()\n\u001b[32m     28\u001b[39m out = model.process_one_cluster(te_runoff, cluster_idx, \n\u001b[32m     29\u001b[39m                                 te_transfer_bucket)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data_prediction005/SYSTEM/prediction002/home/tristan/conda_envs/diffhydro/lib/python3.13/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data_prediction005/SYSTEM/prediction002/home/tristan/conda_envs/diffhydro/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data_prediction005/SYSTEM/prediction002/home/tristan/conda_envs/diffhydro/lib/python3.13/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for cluster_idx in tqdm(range(len(model.params))):\n",
    "    nodes = g[cluster_idx].nodes    \n",
    "    pbar = tqdm(range(n_iter), desc=\"Training\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tr_transfer_bucket = model.init_upstream_discharges(ci.yield_all_runoffs(tr_runoff_pix), cluster_idx)\n",
    "        te_transfer_bucket = model.init_upstream_discharges(ci.yield_all_runoffs(te_runoff_pix), cluster_idx)\n",
    "    \n",
    "    tr_runoff = ci.interpolate_runoff(tr_runoff_pix, cluster_idx)\n",
    "    te_runoff = ci.interpolate_runoff(te_runoff_pix, cluster_idx)\n",
    "    \n",
    "    assert pd.Series(nodes).isin(tr_discharge.columns).all()\n",
    "    assert pd.Series(nodes).isin(te_discharge.columns).all()\n",
    "    \n",
    "    tr_y = tr_discharge[nodes]\n",
    "    te_y = te_discharge[nodes]\n",
    "\n",
    "    for _ in pbar:\n",
    "        out = model.process_one_cluster(tr_runoff, cluster_idx, \n",
    "                                        tr_transfer_bucket)\n",
    "        tr_nse = nse_fn(out.values, tr_y.values).mean()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss = 1-tr_nse\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        out = model.process_one_cluster(te_runoff, cluster_idx, \n",
    "                                        te_transfer_bucket)\n",
    "        te_nse = nse_fn(out.values, te_y.values).mean()\n",
    "        \n",
    "        pbar.set_postfix({\"Tr NSE:\": tr_nse.item(), \"Te NSE\":te_nse.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df6180-5337-4a7e-bbdd-8a70570ebc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59aa00-8ed3-49f4-bd12-844972d6547f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59486a24-5857-4c9e-beec-f9a233997b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutingDataset():\n",
    "    def __init__(self, runoff_inp, discharge_lbl, seq_len):\n",
    "        assert (runoff_inp.index==discharge_lbl.index).all()\n",
    "        self.runoff_inp=runoff_inp\n",
    "        self.discharge_lbl=discharge_lbl\n",
    "        self.seq_len=seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = slice(self.self.runoff_inp.index[idx],\n",
    "                      self.self.runoff_inp.index[idx+seq_len])\n",
    "        return self.runoff_inp[:,slice], self.discharge_lbl[:,slice]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.discharge_lbl.index) - self.seq_len\n",
    "\n",
    "    def random_sequence(self, n_samples):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
