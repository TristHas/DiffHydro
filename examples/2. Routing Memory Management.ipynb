{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebb1812-6f8f-4486-8507-03db7361f4a0",
   "metadata": {},
   "source": [
    "### GPU Memory optimization\n",
    "\n",
    "DiffRoute accelerates LTI routing computations by factoring computations in an embarassingly parallel formulation.\n",
    "This formulation of the routing procedure induces memory overhead and redundant computations.\n",
    "\n",
    "In technical terms, DiffRoute explictly instantiates a routing kernel along the transitive closure of the river network.\n",
    "For large river network, the memory footprint of the kernel becomes a bottleneck.\n",
    "To handle such large workloads within memory bounds, a number of helper functionalities are proposed.\n",
    "\n",
    "This notebook discusses the GPU memory bottleneck that arises in routing through large river networks and presents the different techniques to navigate this limitation.\n",
    "\n",
    "% Actually there are two limitations: \n",
    "(i) the kernel\n",
    "(2) the input/output time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685ba93c-ca8c-4afe-80eb-55be01e0f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from diffhydro import (LTIRouter, LTIStagedRouter, DataTensor, StagedCatchmentInterpolator)\n",
    "from diffhydro.io import read_rapid_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247abba-46be-4dde-be8a-c68d7e423c5a",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449badee-5faf-4280-aa15-556e680ee465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing model parameterss\n",
    "max_delay = 32\n",
    "dt = 1/24\n",
    "# Experiment pathes and variables\n",
    "device = \"cuda:1\"\n",
    "root = Path(\"./data\") # Set a data root path with enough disk space (>100MB)\n",
    "root = Path(\"../../../DiffHydro/examples/data\") # Set a data root path with enough disk space (>100MB)\n",
    "rapid_path = root / \"geoglows\" / \"rapid_config\" / \"305\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10a7aa-2946-475c-87ce-78f9233467a5",
   "metadata": {},
   "source": [
    "### Download data if necessary\n",
    "\n",
    "Downloads can take time, only execute this cell if you have not previously downloaded the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "164b6720-c1a0-477f-9a2a-194ac14fc6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9eb305cb284303b037bb3cfd38c3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 305_daily_sparse_runoff.feather:   0%|          | 0.00/46.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea6bdf540a2455897bd6e6424076b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 305_interp_weight.feather:   0%|          | 0.00/465k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataTensor' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m download_single_vpu_data\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdownload_single_vpu_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Should format to RAPID.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data_prediction005/SYSTEM/prediction002/home/tristan/workspace/rivers/diffroute_reviews/DiffHydro/examples/utils/download.py:149\u001b[39m, in \u001b[36mdownload_single_vpu_data\u001b[39m\u001b[34m(root)\u001b[39m\n\u001b[32m    144\u001b[39m download_zenodo_file(\n\u001b[32m    145\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://zenodo.org/records/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mZENODO_RECORD\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/files/305_interp_weight.feather\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mstr\u001b[39m(dest_path),\n\u001b[32m    147\u001b[39m )\n\u001b[32m    148\u001b[39m download_rapid_config(root, \u001b[32m305\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[43mprocess_single_vpu_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data_prediction005/SYSTEM/prediction002/home/tristan/workspace/rivers/diffroute_reviews/DiffHydro/examples/utils/download.py:128\u001b[39m, in \u001b[36mprocess_single_vpu_data\u001b[39m\u001b[34m(root, device)\u001b[39m\n\u001b[32m    126\u001b[39m g = read_rapid_graph(rapid_path)\n\u001b[32m    127\u001b[39m cat = CatchmentInterpolator(g, pixel_runoff, interp_df).to(device)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m runoff = \u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_runoff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Dump as netcdf\u001b[39;00m\n\u001b[32m    130\u001b[39m batch_index = runoff.coords[BATCH_DIM][\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data_prediction005/SYSTEM/prediction002/home/tristan/conda_envs/diffhydro/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data_prediction005/SYSTEM/prediction002/home/tristan/conda_envs/diffhydro/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data_prediction005/SYSTEM/prediction002/home/tristan/workspace/rivers/diffroute_reviews/DiffHydro/diffhydro/interp/cat_interp.py:147\u001b[39m, in \u001b[36mCatchmentInterpolator.forward\u001b[39m\u001b[34m(self, inp)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp):\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, DataTensor):\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterpolate_runoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, SparseKernel):\n\u001b[32m    149\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.interpolate_kernel(inp.values, inp.coords)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data_prediction005/SYSTEM/prediction002/home/tristan/workspace/rivers/diffroute_reviews/DiffHydro/diffhydro/interp/cat_interp.py:124\u001b[39m, in \u001b[36mCatchmentInterpolator.interpolate_runoff\u001b[39m\u001b[34m(self, runoff)\u001b[39m\n\u001b[32m    121\u001b[39m weighted_x = runoff.values[:, \u001b[38;5;28mself\u001b[39m.src_idxs] * \u001b[38;5;28mself\u001b[39m.weights[\u001b[38;5;28;01mNone\u001b[39;00m, :, \u001b[38;5;28;01mNone\u001b[39;00m]  \u001b[38;5;66;03m# broadcasts over the time dimension\u001b[39;00m\n\u001b[32m    122\u001b[39m out_size = runoff.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.n_cats, runoff.shape[-\u001b[32m1\u001b[39m]\n\u001b[32m    123\u001b[39m out = torch.zeros(out_size, \n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m                   dtype=\u001b[43mrunoff\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m, device=runoff.device)\n\u001b[32m    125\u001b[39m out.index_add_(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.dest_idxs, weighted_x)\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m datatensor_from_components(\n\u001b[32m    127\u001b[39m     out,\n\u001b[32m    128\u001b[39m     batch_coords=runoff.coords[\u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    129\u001b[39m     spatial_coords=to_coord_sequence(\u001b[38;5;28mself\u001b[39m.map_out),\n\u001b[32m    130\u001b[39m     time_coords=runoff.coords[TIME_DIM],\n\u001b[32m    131\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataTensor' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "from utils.download import download_single_vpu_data\n",
    "download_single_vpu_data(root) # Should format to RAPID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d826872-9da4-4c19-9131-84768a1fcfb9",
   "metadata": {},
   "source": [
    "### Load input runoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4470b7-060f-4c93-8645-dc4192386cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runoff_xr = xr.open_dataarray(rapid_path / \"runoff.nc\")\n",
    "runoff_xr = runoff_xr.rename({\"river_id\":\"spatial\"}).expand_dims(\"batch\").transpose(\"batch\", \"spatial\", \"time\")\n",
    "runoff = DataTensor.from_dataarray(runoff_xr).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce372891-a073-475f-834e-55ef62c2915b",
   "metadata": {},
   "source": [
    "### 0. Basic Routing\n",
    "\n",
    "This is a recap of the previous notebook for \"normal\" routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3825e2-e042-4162-a510-5a2b7c6d8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph\n",
    "g = read_rapid_graph(rapid_path).to(device)\n",
    "# Instantiate the routing model\n",
    "model = LTIRouter(max_delay=max_delay, dt=dt).to(device)\n",
    "# Execute routing\n",
    "discharges = model(runoff, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690695b-b312-4e2b-b3a3-fed2ef165a61",
   "metadata": {},
   "source": [
    "### 1. Kernel memory footprint reduction with staged routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a1ea6-c7ae-48ec-9857-61ccd9353079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph partitioning parameters\n",
    "plength_thr = 10**4\n",
    "node_thr = 10**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a68ee-2d01-47c8-8b3c-04a98422f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = read_rapid_graph(rapid_path, \n",
    "                     plength_thr=plength_thr, \n",
    "                     node_thr=node_thr).to(device)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135a559-a45a-452c-8b57-0bd5bf2b6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LTIStagedRouter(max_delay=max_delay, dt=dt).to(device)\n",
    "discharges = model(runoff, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecae6e1-cc9b-4d01-8f7f-47abd6d052f7",
   "metadata": {},
   "source": [
    "### 2. Time series footprint reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa77ac-4d76-4ac3-b7d3-1a8e09e5781b",
   "metadata": {},
   "source": [
    "#### 2.1 Chunk routing in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9195a-bd7e-4275-8999-84bd8e537ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_chunk_generator(datatensor, chunk_size, init_window):\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def coalesce_time_chunks(chunk_seq, init_window):\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c872a05-e1df-4c46-ae79-3015fdac77f6",
   "metadata": {},
   "source": [
    "#### 2.2 Chunk routing in space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416d3c7-09e4-44da-bc5e-2294fb2717f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b937023-357c-49ae-b0b7-c0849b93c1d7",
   "metadata": {},
   "source": [
    "#### 2.3 On-the-fly catchment aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7bd8a-763f-4577-9afc-bb60ededa079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3a8196e-6f47-49dc-8f19-cd99624606ea",
   "metadata": {},
   "source": [
    "#### 2.4 Manage memory transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd38f4e-b051-4b73-8454-e2060595e0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12d9c95e-2a1b-4426-aec5-85c805b5b2d5",
   "metadata": {},
   "source": [
    "### Kernel memory reduction: Route with sub-cluster stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "601c4bb3-6999-4636-8936-75d24381d57a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Upstream stats computations ... ####\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109f7d47b5304aa4a22fcb54d1cb5b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing breakpoints:   0%|          | 0/15562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Segmentation into subgraphs ... ####\n",
      "Removing edges...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4627c6a120af4b8fbe4bd46c174e8e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment graph into connected components....\n",
      "Build subgraphs for each cluster and node-cluster map...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb432b8874145de9daab4ac513fc4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establish dependencies between clusters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed90ed7240424f04ad992e916376cf88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Grouping subgraphs to cluster and infering dependencies ... ####\n",
      "Initialize dependencies...\n",
      "Associate clusters for remaining subgraphs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0a57b0081c463182aed923e5702bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging graphs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae948306a3824669ad07a23e0664445f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing merged graphs node idxs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68ab68d9c534fbb88cbb41e3cf86d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match breakpoint nodes across clusters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04585928beb45dfa19ff6edffdda3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feadbab732d14251a7952113b3a7eba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the routing graph defined as a RAPID project into a RivTree structure\n",
    "g = read_rapid_graph(rapid_config_path, \n",
    "                     plength_thr=plength_thr, \n",
    "                     node_thr=node_thr).to(device)\n",
    "\n",
    "# Load input runoff.\n",
    "# Here the data is provided as pixel-wise runoffs.\n",
    "pixel_runoff = pd.read_feather(runoff_path)  / (3600. * 24) # Convert values in m3 / s\n",
    "pixel_runoff = TimeSeriesThDF.from_pandas(pixel_runoff).to(device) # Convert pandas DataFrame to TimeSeriesThDF\n",
    "\n",
    "# Interpolate the pixel-wise runoffs onto the graph catchments \n",
    "interp_df = pd.read_feather(interp_weight_path)\n",
    "cat = StagedCatchmentInterpolator(g, pixel_runoff, interp_df).to(device) \n",
    "\n",
    "model = LTIStagedRouter(max_delay=max_delay, dt=dt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d0a22c8-480d-4690-8b25-38acd99efa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "runoff = cat.interpolate_all_runoff(pixel_runoff)\n",
    "discharges = model(runoff, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3d626-9448-44f4-9cf1-e570209fe9aa",
   "metadata": {},
   "source": [
    "### Time series memory reduction: Route with sub-cluster stages Iterative routing of sub-cluster with on-the fly catchment interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6363ba6-a503-4985-b95e-e6d2c0ec3d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we create a generator of per-cluster input runoff time series\n",
    "runoff = cat.yield_all_runoffs(pixel_runoff)\n",
    "type(runoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6d8b211-a500-4051-8285-ab657e9a1e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we create a generator of per-cluster output discharge time series\n",
    "discharges = model.route_all_clusters_yield(runoff, g)\n",
    "type(discharges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9aa91f3-c494-4b22-8597-78fbb0c443d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 contains river channels [360038401 360049008 360056494 360060030 360060238]\n",
      "Cluster 1 contains river channels [360038400 360042353 360053793 360054001 360054209]\n",
      "Cluster 2 contains river channels [360050178 360046227 360049556 360054758 360053511]\n",
      "Cluster 3 contains river channels [360046093 360046301 360046509 360052124 360052332]\n",
      "Cluster 4 contains river channels [360029711 360032415 360028048 360028256 360025138]\n",
      "Cluster 5 contains river channels [360028673 360024096 360030126 360030334 360036574]\n",
      "Cluster 6 contains river channels [360023043 360028868 360035526 360035734 360035942]\n",
      "Cluster 7 contains river channels [360030211 360044355 360052051 360052259 360055796]\n",
      "Cluster 8 contains river channels [360069121 360069329 360071203 360071411 360071619]\n",
      "Cluster 9 contains river channels [360030208 360030416 360029585 360056418 360047683]\n",
      "Cluster 10 contains river channels [360061444 360061652 360073092 360071221 360062070]\n",
      "Cluster 11 contains river channels [360061455 360061663 360061871 360062079 360063744]\n",
      "Cluster 12 contains river channels [360039424 360039632 360039840 360040048 360041089]\n",
      "Cluster 13 contains river channels [360053770 360061464 360047737 360047945 360053978]\n",
      "Cluster 14 contains river channels [360025605 360023942 360029765 360024150 360033304]\n",
      "Cluster 15 contains river channels [360051074 360051282 360051490 360051698 360051906]\n",
      "Cluster 16 contains river channels [360039432 360044838 360055234 360045457 360045665]\n",
      "Cluster 17 contains river channels [360068100 360058947 360059987 360060195 360069556]\n",
      "Cluster 18 contains river channels [360064770 360064978 360067474 360067682 360067890]\n"
     ]
    }
   ],
   "source": [
    "# Looping over the output discharges triggers both the catchment interpolation and routing execution.\n",
    "for i,d in enumerate(discharges):\n",
    "    print(f\"Cluster {i} contains river channels {d.columns[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e8cc2-b89c-426c-948c-b7726d0f2db1",
   "metadata": {},
   "source": [
    "### Further time-series memory reduction by keeping runoff time series on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b19b3-409c-4ab2-942a-108a3bf704b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9250a-fdd1-49c3-812a-b00641d4a407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38bd9521-43b2-4cee-a6a2-4a9ffcb1b998",
   "metadata": {},
   "source": [
    "### Further time-series memory reduction: tiling in time\n",
    "\n",
    "Finally, if the cost of routing remains too high, even through small clusters and dedicated CPU-GPU memory transfers, it is possible to chunk the time series in time and iterate over these chunks.\n",
    "\n",
    "We shall provide an example for doing so shortly.\n",
    "\n",
    "If you need this functionality, please reach out to us so we can adapt an implementation that suits your needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
